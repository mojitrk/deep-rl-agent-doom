{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "precious-parker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gym\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
    "import argparse\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import VecTransposeImage, VecFrameStack, DummyVecEnv\n",
    "from vizdoom.vizdoom import Mode\n",
    "from vizdoom.vizdoom import ScreenFormat\n",
    "from environments import doom_env\n",
    "from environments import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "entitled-tribe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "employed-microwave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticCnnPolicy(\n",
       "  (features_extractor): CNNFeatureExtractor(\n",
       "    (cnn): Sequential(\n",
       "      (0): LayerNorm((12, 100, 156), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Conv2d(12, 32, kernel_size=(8, 8), stride=(4, 4), bias=False)\n",
       "      (2): LayerNorm((32, 24, 38), eps=1e-05, elementwise_affine=True)\n",
       "      (3): LeakyReLU(negative_slope=0.1)\n",
       "      (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
       "      (5): LayerNorm((64, 11, 18), eps=1e-05, elementwise_affine=True)\n",
       "      (6): LeakyReLU(negative_slope=0.1)\n",
       "      (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (8): LayerNorm((64, 9, 16), eps=1e-05, elementwise_affine=True)\n",
       "      (9): LeakyReLU(negative_slope=0.1)\n",
       "      (10): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=9216, out_features=512, bias=False)\n",
       "      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (shared_net): Sequential()\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=256, out_features=18, bias=True)\n",
       "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = r'/home/leandro/ml/rl-doom/trained_agents/deathmatch_512_256-256_stack=4/best_model.zip'\n",
    "agent = PPO.load(model_path)\n",
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "protecting-webster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built action space of size 18 from buttons [<Button.ATTACK: 0>, <Button.MOVE_FORWARD: 13>, <Button.MOVE_LEFT: 11>, <Button.MOVE_RIGHT: 10>, <Button.TURN_RIGHT: 14>, <Button.TURN_LEFT: 15>]\n",
      "['M']\n",
      "Logging with ID 4F\n"
     ]
    }
   ],
   "source": [
    "from config import EnvironmentConfig\n",
    "\n",
    "env_config = EnvironmentConfig({\n",
    "    \"scenario\": \"bots_deathmatch_multimaps\",\n",
    "    \"type\": \"singleplayer\",\n",
    "    \"args\": {\n",
    "      \"maps\": [\"M\", \"M_R\"],\n",
    "      \"bots\": 8,\n",
    "      \"curriculum\": False,\n",
    "      \"shaping\": True\n",
    "    },\n",
    "    \"vizdoom_mode\": \"PLAYER\",\n",
    "    \"n_parallel\": 4,\n",
    "    \"frame_skip\": 1,\n",
    "    \"frame_stack\": 4,\n",
    "    \"action_combination\": True,\n",
    "    \"action_noop\": False,\n",
    "    \"obs_width\": 320,\n",
    "    \"obs_height\": 240,\n",
    "    \"obs_channels\": 3,\n",
    "    \"obs_crop\": [\n",
    "      40,\n",
    "      4,\n",
    "      0,\n",
    "      4\n",
    "    ],\n",
    "    \"obs_resize\": [\n",
    "      0.5,\n",
    "      0.5\n",
    "    ]\n",
    "  })\n",
    "\n",
    "env = VecTransposeImage(\n",
    "   VecFrameStack(\n",
    "        DummyVecEnv([lambda: utils.create_env_with_bots(env_config, eval=True)]),\n",
    "        4\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "numeric-capture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "AGENT: 0\n",
      "************************\n",
      "Agent 4F frags: 0, deaths: 0, total reward: 0\n",
      "- frag: +0.0\n",
      "- damage: +0.0\n",
      "- ammo: +0.0\n",
      "- health: +0.0\n",
      "- armor: +0.0\n",
      "- distance: +0.0\n",
      "************************\n",
      "Results:\n",
      "Dredd: 0\n",
      "Conan: 0\n",
      "Plissken: 1\n",
      "T800: 1\n",
      "Predator: 1\n",
      "McClane: 1\n",
      "Rambo: 1\n",
      "MacGyver: 2\n",
      "AGENT: 7\n",
      "************************\n",
      "Agent 4F frags: 7.0, deaths: 1, total reward: 13.303499999999987\n",
      "- frag: +7.0\n",
      "- damage: +7.2\n",
      "- ammo: +0.3\n",
      "- health: -1.4\n",
      "- armor: +0.0\n",
      "- distance: +0.2\n",
      "************************\n",
      "Results:\n",
      "Bond: 0\n",
      "Leone: 1\n",
      "Blazkowicz: 1\n",
      "T800: 1\n",
      "Machete: 1\n",
      "Conan: 1\n",
      "MacGyver: 2\n",
      "Predator: 3\n",
      "AGENT: 7\n",
      "************************\n",
      "Agent 4F frags: 7.0, deaths: 2, total reward: 14.146500000000184\n",
      "- frag: +7.0\n",
      "- damage: +8.6\n",
      "- ammo: +0.8\n",
      "- health: -2.8\n",
      "- armor: +0.0\n",
      "- distance: +0.5\n",
      "************************\n",
      "Results:\n",
      "Leone: 0\n",
      "Conan: 1\n",
      "McClane: 1\n",
      "Anderson: 1\n",
      "Bond: 1\n",
      "Ripley: 1\n",
      "Plissken: 2\n",
      "Blazkowicz: 3\n",
      "AGENT: 9\n",
      "************************\n",
      "Agent 4F frags: 9.0, deaths: 1, total reward: 16.745499999999925\n",
      "- frag: +9.0\n",
      "- damage: +8.2\n",
      "- ammo: +0.3\n",
      "- health: -1.3\n",
      "- armor: +0.0\n",
      "- distance: +0.5\n",
      "************************\n",
      "Results:\n",
      "McClane: 0\n",
      "Ripley: 0\n",
      "Anderson: 0\n",
      "Bond: 1\n",
      "Blazkowicz: 1\n",
      "Dredd: 1\n",
      "Machete: 1\n",
      "Leone: 2\n",
      "AGENT: 9\n",
      "************************\n",
      "Agent 4F frags: 9.0, deaths: 1, total reward: 17.511499999999916\n",
      "- frag: +9.0\n",
      "- damage: +8.2\n",
      "- ammo: +0.1\n",
      "- health: -0.2\n",
      "- armor: +0.0\n",
      "- distance: +0.4\n",
      "************************\n",
      "Results:\n",
      "T800: 0\n",
      "Dredd: 1\n",
      "Machete: 1\n",
      "Plissken: 1\n",
      "Leone: 1\n",
      "McClane: 1\n",
      "Predator: 1\n",
      "Anderson: 2\n",
      "AGENT: 8\n",
      "************************\n",
      "Agent 4F frags: 8.0, deaths: 0, total reward: 15.490499999999956\n",
      "- frag: +8.0\n",
      "- damage: +7.9\n",
      "- ammo: +0.2\n",
      "- health: -0.9\n",
      "- armor: +0.0\n",
      "- distance: +0.2\n",
      "************************\n",
      "Results:\n",
      "Leone: 0\n",
      "Dredd: 0\n",
      "Blazkowicz: 0\n",
      "Ripley: 0\n",
      "Anderson: 1\n",
      "Jones: 1\n",
      "MacGyver: 2\n",
      "Bond: 2\n",
      "AGENT: 8\n",
      "************************\n",
      "Agent 4F frags: 8.0, deaths: 1, total reward: 16.612500000000047\n",
      "- frag: +8.0\n",
      "- damage: +8.1\n",
      "- ammo: +1.4\n",
      "- health: -1.2\n",
      "- armor: +0.0\n",
      "- distance: +0.4\n",
      "************************\n",
      "Results:\n",
      "Machete: 0\n",
      "Ripley: 0\n",
      "Bond: 1\n",
      "Plissken: 1\n",
      "Conan: 1\n",
      "McClane: 1\n",
      "Predator: 2\n",
      "Dredd: 4\n",
      "AGENT: 9\n",
      "************************\n",
      "Agent 4F frags: 9.0, deaths: 2, total reward: 16.345499999999994\n",
      "- frag: +9.0\n",
      "- damage: +7.9\n",
      "- ammo: +1.0\n",
      "- health: -2.0\n",
      "- armor: +0.0\n",
      "- distance: +0.4\n",
      "************************\n",
      "Results:\n",
      "Blazkowicz: 0\n",
      "McClane: 1\n",
      "Rambo: 1\n",
      "Dredd: 1\n",
      "Plissken: 1\n",
      "Anderson: 2\n",
      "Ripley: 3\n",
      "MacGyver: 4\n",
      "AGENT: 7\n",
      "************************\n",
      "Agent 4F frags: 7.0, deaths: 3, total reward: 14.275500000000124\n",
      "- frag: +7.0\n",
      "- damage: +9.2\n",
      "- ammo: +0.5\n",
      "- health: -2.8\n",
      "- armor: +0.0\n",
      "- distance: +0.4\n",
      "************************\n",
      "Results:\n",
      "Ripley: 0\n",
      "Blazkowicz: 1\n",
      "Machete: 1\n",
      "Dredd: 1\n",
      "Predator: 1\n",
      "Plissken: 2\n",
      "McClane: 3\n",
      "Anderson: 3\n",
      "AGENT: 9\n",
      "************************\n",
      "Agent 4F frags: 9.0, deaths: 3, total reward: 16.70549999999995\n",
      "- frag: +9.0\n",
      "- damage: +9.4\n",
      "- ammo: +0.9\n",
      "- health: -3.0\n",
      "- armor: +0.0\n",
      "- distance: +0.4\n",
      "************************\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import time\n",
    "\n",
    "frame_limit = 30*35\n",
    "frame_start = 350\n",
    "j = 0\n",
    "\n",
    "for i in range(10):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    images = []\n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        \n",
    "        if j > frame_start:\n",
    "            images.append(env.venv.envs[0].game.get_state().screen_buffer)\n",
    "        j += 1\n",
    "        \n",
    "        if j > frame_start + frame_limit:\n",
    "            j = 0\n",
    "            break\n",
    "            \n",
    "        #time.sleep(0.02)\n",
    "\n",
    "    imageio.mimsave(f'../figures/deathmatch_stack=4_{i}.gif', images, fps=35)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "prerequisite-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-cycle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
